{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pythonによるスクレイピング＆機械学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ip]\nAPI_URI=http://api.aoikujira.com/ip/get.php\nREMOTE_ADDR=126.40.131.123\nREMOTE_HOST=softbank126040131123.bbtec.net\nREMOTE_PORT=59498\nHTTP_HOST=api.aoikujira.com\nHTTP_USER_AGENT=Python-urllib/3.6\nHTTP_ACCEPT_LANGUAGE=\nHTTP_ACCEPT_CHARSET=\nSERVER_PORT=80\nFORMAT=ini\n\n\nurl= http://api.aoikujira.com/zip/xml/get.php?fmt=xml&zn=9601402\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<address result=\"1\">\n<header>\n  <result>1</result>\n  <api>api.aoikujira.com/zip</api>\n  <version>1.1</version>\n</header>\n<value>\n  <zip>9601402</zip>\n  <ken>福島県</ken>\n  <shi>伊達郡川俣町</shi>\n  <cho>小綱木</cho>\n  <disp>福島県伊達郡川俣町小綱木</disp>\n  <kenkana>フクシマケン</kenkana>\n  <shikana>ダテグンカワマタマチ</shikana>\n  <chokana>コツナギ</chokana>\n</value>\n</address>\n"
     ]
    }
   ],
   "source": [
    "#IP確認APIアクセスして結果を表示する\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "#データを取得する\n",
    "url = \"http://api.aoikujira.com/ip/ini\"\n",
    "res = urllib.request.urlopen(url)\n",
    "data = res.read()\n",
    "\n",
    "#バイナリを文字列に変換\n",
    "text = data.decode(\"UTF-8\")\n",
    "print(text)\n",
    "\n",
    "API = \"http://api.aoikujira.com/zip/xml/get.php\"\n",
    "\n",
    "#住所をよんで変換する\n",
    "#パラメーターをURLエンコードする\n",
    "\n",
    "values = {\n",
    "    'fmt':'xml',\n",
    "    'zn':'9601402'}\n",
    "params = urllib.parse.urlencode(values)\n",
    "\n",
    "#リクエスト用のURLを作成\n",
    "url2 = API + \"?\" +params\n",
    "print(\"url=\",url2)\n",
    "\n",
    "#ダウンロード\n",
    "data2 = urllib.request.urlopen(url2).read()\n",
    "text2 = data2.decode(\"utf-8\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://api.aoikujira.com/hyakunin/get.php?fmt=ini&key=%E7%A7%8B%E3%81%AE%E7%94%B0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[item1]\nkami=秋の田の かりほの庵の 苫をあらみ\nsimo=我が衣手は 露にぬれつつ\nkami_kana=あきのたのかりほのいほのとまをあらみ\nsimo_kana=わかころもてはつゆにぬれつつ\nsakusya=天智天皇\n\n\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "#コマンドラインの引数を得る。\n",
    "if len(sys.argv) <= 1:\n",
    "    print(\"USAGE: hyakunin.py(keyword)\")\n",
    "    sys.exit()\n",
    "keyword = sys.argv[1]\n",
    "\n",
    "#パラメーターをURLエンコードする\n",
    "API = \"http://api.aoikujira.com/hyakunin/get.php\"\n",
    "query = {\n",
    "    \"fmt\":\"ini\",\n",
    "    \"key\": \"秋の田\"\n",
    "}\n",
    "params = parse.urlencode(query)\n",
    "url = API + \"?\" + params\n",
    "print(\"url=\",url)\n",
    "\n",
    "#ダウンロード\n",
    "with req.urlopen(url) as r :\n",
    "    b = r.read()\n",
    "    data = b.decode('utf-8')\n",
    "    print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAGE: Input keyword\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7c97b441d439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# if len(sys.argv) <= 1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"USAGE: Input keyword\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#コマンドラインが使えないのでインプットすることにした。JupyterNoteだとうまく動かない。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             raise StdinNotImplementedError(\n\u001b[1;32m--> 699\u001b[1;33m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m             )\n\u001b[0;32m    701\u001b[0m         return self._input_request(str(prompt),\n",
      "\u001b[1;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "#コマンドラインの引数を得る。\n",
    "# if len(sys.argv) <= 1:\n",
    "print(\"USAGE: Input keyword\")\n",
    "keyword = input()\n",
    "#コマンドラインが使えないのでインプットすることにした。JupyterNoteだとうまく動かない。\n",
    "\n",
    "\n",
    "\n",
    "#パラメーターをURLエンコードする\n",
    "API = \"http://api.aoikujira.com/hyakunin/get.php\"\n",
    "query = {\n",
    "    \"fmt\":\"ini\",\n",
    "    \"key\": keyword\n",
    "}\n",
    "params = parse.urlencode(query)\n",
    "url = API + \"?\" + params\n",
    "print(\"url=\",url)\n",
    "\n",
    "#ダウンロード\n",
    "with req.urlopen(url) as r :\n",
    "    b = r.read()\n",
    "    data = b.decode('utf-8')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAGE: Input keyword\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e829bc21a80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# if len(sys.argv) <= 1:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"USAGE: Input keyword\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#コマンドラインが使えないのでインプットすることにした。JupyterNoteだとうまく動かない。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             raise StdinNotImplementedError(\n\u001b[1;32m--> 699\u001b[1;33m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m             )\n\u001b[0;32m    701\u001b[0m         return self._input_request(str(prompt),\n",
      "\u001b[1;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# import sys\n",
    "# import urllib.request as req\n",
    "# import urllib.parse as parse\n",
    "\n",
    "#コマンドラインの引数を得る。\n",
    "# if len(sys.argv) <= 1:\n",
    "print(\"USAGE: Input keyword\")\n",
    "keyword = input()\n",
    "#コマンドラインが使えないのでインプットすることにした。JupyterNoteだとうまく動かない。\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = スクレイピングとは?\np = webページを解析すること。\np = 任意の箇所を抽出すること。\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#解析したいHTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "   <h1>スクレイピングとは?</h1>\n",
    "   <p>webページを解析すること。</p>\n",
    "   <p>任意の箇所を抽出すること。</p>\n",
    "   </body></html>\n",
    "   \"\"\"\n",
    "\n",
    "#HTMLを解析する\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#任意の部分を抽出する。\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "#要素のテキストを表示する\n",
    "print(\"h1 = \"+ h1.string)\n",
    "print(\"p = \"+ p1.string)\n",
    "print(\"p = \"+ p2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = スクレイピングとは?\n#body = webページから任意のデータを抽出すること。\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#解析したいHTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "   <h1 id=\"title\"> スクレイピングとは?</h1>\n",
    "   <p id=\"body\">webページから任意のデータを抽出すること。</p>\n",
    " </body></html>\n",
    "   \"\"\"\n",
    "\n",
    "#HTMLを解析する\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#findメソッドで取り出す。\n",
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "#テキスト部分を表示\n",
    "print(\"#title =\"+ title.string)\n",
    "print(\"#body = \"+ body.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uta > http://uta.pw\noto > http://oto.chu.jp\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#解析したいHTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    " <ul>\n",
    "  <li><a href=\"http://uta.pw\">uta</a></li>\n",
    "  <li><a href=\"http://oto.chu.jp\">oto</a></li>\n",
    " </ul>\n",
    " </body></html>\n",
    "\"\"\"\n",
    "\n",
    "#HTMLを解析する\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#findメソッドで取り出す。\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "#リンクの一覧を表示\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">\",href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アメリカドル売り買い= 110.523\nアメリカドル売り買い= 110.527\n株式ランキングから= 値上がり率2521社1. 明治機+31.25％2. ホロン+25.91％3. ソレイジア+22.51％4. ヤガミ+20.88％5. 中村超硬+20.82％もっと見る値下がり率1109社1. エクストリ-26.78％2. ETFS パラ…-20.10％3. 日ファルコ-18.32％4. ダブルＳ-15.38％5. ＮＦＫＨＤ-14.50％もっと見る出来高1. ティアック2. みずほＦＧ3. ＡＤワーク4. 三菱ＵＦＪ5. ソレイジアもっと見る銘柄別投稿数1. エクストリ2. ＦＧＩ3. リミックス4. ビートＨＤ5. テリロジーもっと見る\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "#HTMLを取得\n",
    "url = \"https://finance.yahoo.co.jp/\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "pricelist = soup.select('div[class=\"dtl\"]')\n",
    "for dtl in pricelist:\n",
    "    print(\"アメリカドル売り買い=\",dtl.string)\n",
    "\n",
    "aaa = soup.select(\"div.boardFinDark\")\n",
    "for boardFinDark in aaa:\n",
    "    print(\"株式ランキングから=\",boardFinDark.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USD/JPY = 110.49487\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "#HTMLを取得\n",
    "url = \"https://api.aoikujira.com/kawase/xml/usd\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "jpy = soup.select_one(\"jpy\").string\n",
    "print(\"USD/JPY =\", jpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "url = \"http://www.aozora.gr.jp/cards/000081/files/46268_23911.html\"\n",
    "\n",
    "browser = webdriver.PhantomJS(executable_path=r'C:\\Users\\Kogure Taichi\\phantomjs-2.1.1-windows\\bin\\phantomjs.exe')\n",
    "browser.implicitly_wait(3)\n",
    "browser.get(url)\n",
    "\n",
    "browser.save_screenshot(\"website.png\")\n",
    "browser.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium で　JavaScriptを動かす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.PhantomJS(executable_path=r'C:\\Users\\Kogure Taichi\\phantomjs-2.1.1-windows\\bin\\phantomjs.exe')\n",
    "browser.implicitly_wait(3)\n",
    "\n",
    "browser.get(\"https://google.com\")\n",
    "\n",
    "# Run JavaScript\n",
    "r = browser.execute_script(\"return 100+50\")\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download =  https://docs.python.jp/3.6/library/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analize_html= https://docs.python.jp/3.6/library/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download =  https://docs.python.jp/3.6/_static/pydoctheme.css\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download =  https://docs.python.jp/3.6/_static/pygments.css\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download =  https://docs.python.jp/3.6/library/intro.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analize_html= https://docs.python.jp/3.6/library/intro.html\ndownload =  https://docs.python.jp/3.6/library/functions.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analize_html= https://docs.python.jp/3.6/library/functions.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download =  https://docs.python.jp/3.6/library/constants.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analize_html= https://docs.python.jp/3.6/library/constants.html\ndownload =  https://docs.python.jp/3.6/library/stdtypes.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analize_html= https://docs.python.jp/3.6/library/stdtypes.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# url丸ごとダウンロード\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://docs.python.jp/3.6/library/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0manalize_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36manalize_html\u001b[1;34m(url, root_url)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".(html|htm)$\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 再帰的にHTMLファイルを解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0manalize_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# それ以外のファイル\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36manalize_html\u001b[1;34m(url, root_url)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".(html|htm)$\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 再帰的にHTMLファイルを解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0manalize_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# それ以外のファイル\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36manalize_html\u001b[1;34m(url, root_url)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".(html|htm)$\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 再帰的にHTMLファイルを解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0manalize_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# それ以外のファイル\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36manalize_html\u001b[1;34m(url, root_url)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\".(html|htm)$\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 再帰的にHTMLファイルを解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0manalize_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# それ以外のファイル\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36manalize_html\u001b[1;34m(url, root_url)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# リンクを抽出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menum_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlink_url\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlink_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_url\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# リンクがルート以外のパスを指していたら無視\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-8e289176bc2b>\u001b[0m in \u001b[0;36menum_links\u001b[1;34m(html, base)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# HTML内にあるリンクを抽出する関数。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0menum_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"link[rel='stylesheet']\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# CSS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mlinks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a[href]\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# link\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# < + letter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"</\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\html\\parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'unexpected call to parse_starttag()'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlasttag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mendpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattrfind_tolerant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#Pythonのマニュアルを再帰的にダウンロード\n",
    "\"\"\"\n",
    "リンク先を全ダウンロードするやりかた。\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import urllib.parse  as parse\n",
    "from os import makedirs\n",
    "import os.path, time, re\n",
    "\n",
    "# 処理済み判断変数\n",
    "proc_files = {}\n",
    "\n",
    "\n",
    "# HTML内にあるリンクを抽出する関数。\n",
    "def enum_links(html, base):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = soup.select(\"link[rel='stylesheet']\")  # CSS\n",
    "    links += soup.select(\"a[href]\")  # link\n",
    "    result = []\n",
    "    # href属性を取り出し、リンクを絶対パスに変換\n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        url = req.urljoin(base, href)\n",
    "        result.append(url)\n",
    "    return result\n",
    "\n",
    "\n",
    "# ファイルをダウンロードし保存する関数\n",
    "def download_file(url):\n",
    "    o = parse.urlparse(url)\n",
    "    savepath = \"./\" + o.netloc + o.path\n",
    "    if re.search(r\"/$\", savepath):  # ディレクトリならindex.path\n",
    "        savepath += \"index.html\"\n",
    "    savedir = os.path.dirname(savepath)\n",
    "    # すでにダウンロード済み？\n",
    "    if os.path.exists(savepath): return savepath\n",
    "    # ダウンロード先のディレクトリを作成\n",
    "    if not os.path.exists(savedir):\n",
    "        makedirs(savedir)\n",
    "    # ファイルをダウンロード\n",
    "    try:\n",
    "        print(\"download = \", url)\n",
    "        req.urlretrieve(url, savepath)\n",
    "        time.sleep(1)  # 礼儀として1秒スリープ\n",
    "        return savepath\n",
    "    except:\n",
    "        print(\"ダウンロード失敗：\", url)\n",
    "        return None\n",
    "\n",
    "\n",
    "# THMLを解析して ダウンロードする関数。\n",
    "def analize_html(url, root_url):\n",
    "    savepath = download_file(url)\n",
    "    if savepath is None: return\n",
    "    if savepath in proc_files: return  # 解析済みなら処理しない\n",
    "    proc_files[savepath] = True\n",
    "    print(\"analize_html=\", url)\n",
    "    # リンクを抽出\n",
    "    html = open(savepath, \"r\", encoding=\"utf-8\").read()\n",
    "    links = enum_links(html, url)\n",
    "    for link_url in links:\n",
    "        if link_url.find(root_url) != 0:  # リンクがルート以外のパスを指していたら無視\n",
    "            if not re.search(r\".css$\", link_url): continue\n",
    "\n",
    "        if re.search(r\".(html|htm)$\", link_url):  # 再帰的にHTMLファイルを解析\n",
    "            analize_html(link_url, root_url)\n",
    "            continue\n",
    "        # それ以外のファイル\n",
    "        download_file(link_url)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  # url丸ごとダウンロード\n",
    "    url = \"https://docs.python.jp/3.6/library/\"\n",
    "    analize_html(url, url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データベースを作ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Apple', 800)\n(2, 'Orange', 780)\n(3, 'Banana', 430)\n(4, 'Greta', 911)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# sqliteのデータベースに接続 --- (※1)\n",
    "dbpath = \"test.sqlite\"\n",
    "conn = sqlite3.connect(dbpath)\n",
    "\n",
    "# テーブルを作成し、データを挿入する --- (※2)\n",
    "cur = conn.cursor()\n",
    "cur.executescript(\"\"\"\n",
    "/* itemsテーブルが既にあれば削除する */\n",
    "DROP TABLE IF EXISTS items;\n",
    "\n",
    "/* テーブルの作成 */\n",
    "CREATE TABLE items(\n",
    "    item_id INTEGER PRIMARY KEY,\n",
    "    name TEXT UNIQUE,\n",
    "    price INTEGER\n",
    ");\n",
    "\n",
    "/* データを挿入  */\n",
    "INSERT INTO items(name, price)VALUES('Apple', 800);\n",
    "INSERT INTO items(name, price)VALUES('Orange', 780);\n",
    "INSERT INTO items(name, price)VALUES('Banana', 430);\n",
    "INSERT INTO items(name, price)VALUES('Greta', 911);\n",
    "\"\"\")\n",
    "# 上記の操作をデータベースに反映させる --- (※3)\n",
    "conn.commit()\n",
    "\n",
    "# データを抽出する --- (※4)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT item_id,name,price FROM items\")\n",
    "item_list = cur.fetchall()\n",
    "# 一行ずつ表示\n",
    "for it in item_list:\n",
    "    print(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Orange', 520)\n(2, 'Mango', 770)\n(3, 'Kiwi', 400)\n(4, 'Grape', 800)\n(5, 'Peach', 940)\n(6, 'Persimmon', 700)\n(7, 'Banana', 400)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# データベースに接続 --- (※1)\n",
    "filepath = \"test2.sqlite\"\n",
    "conn = sqlite3.connect(filepath)\n",
    "\n",
    "# テーブルを作成 --- (※2)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP TABLE IF EXISTS items\") \n",
    "cur.execute(\"\"\" CREATE TABLE items (\n",
    "    item_id INTEGER PRIMARY KEY,\n",
    "    name    TEXT,\n",
    "    price   INTEGER)\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# 単発でデータを挿入 --- (※3)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\n",
    "    \"INSERT INTO items (name,price) VALUES (?,?)\",\n",
    "    (\"Orange\", 520))\n",
    "conn.commit()\n",
    "\n",
    "# 連続でデータを挿入 --- (※4)\n",
    "cur = conn.cursor()\n",
    "data = [(\"Mango\",770), (\"Kiwi\",400), (\"Grape\",800),\n",
    "    (\"Peach\",940),(\"Persimmon\",700),(\"Banana\", 400)]\n",
    "cur.executemany(\n",
    "    \"INSERT INTO items(name,price) VALUES (?,?)\",\n",
    "    data)\n",
    "conn.commit()\n",
    "\n",
    "# XXX-YYY円のデータを抽出して表示 --- (※5)\n",
    "cur = conn.cursor()\n",
    "price_range = (100, 1000)\n",
    "cur.execute(\n",
    "    \"SELECT * FROM items WHERE price>=? AND price<=?\",\n",
    "    price_range)\n",
    "fr_list = cur.fetchall()\n",
    "for fr in fr_list:\n",
    "    print(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エクセルファイルを開く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 鳥取県 588667\n2 島根県 717397\n3 高知県 764456\n4 徳島県 785491\n5 福井県 806314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\openpyxl\\reader\\worksheet.py:318: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "filename = \"population.xlsx\"\n",
    "book = openpyxl.load_workbook(filename)\n",
    "#先頭のシートを得る\n",
    "sheet = book.worksheets[0]\n",
    "\n",
    "#シートの各行を順に得る\n",
    "data = []\n",
    "for row in sheet.rows:\n",
    "    data.append([\n",
    "        # row[0].value,\n",
    "        row[2].value\n",
    "    ])\n",
    "#先頭行は説明なので捨てる。\n",
    "del data[0]\n",
    "\n",
    "#データを人口別に並び替える\n",
    "data = sorted(data,key =lambda x:x[1])\n",
    "#ワースト５を表示\n",
    "for i, a in enumerate(data):\n",
    "    if(i>=5): break\n",
    "    print(i+1,a[0],int(a[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['鳥取県', 588667],\n ['島根県', 717397],\n ['高知県', 764456],\n ['徳島県', 785491],\n ['福井県', 806314],\n ['佐賀県', 849788],\n ['山梨県', 863075],\n ['香川県', 995842],\n ['和歌山県', 1002198],\n ['秋田県', 1085997],\n ['富山県', 1093247],\n ['宮崎県', 1135233],\n ['山形県', 1168924],\n ['石川県', 1169788],\n ['大分県', 1196529],\n ['岩手県', 1330147],\n ['青森県', 1373339],\n ['沖縄県', 1392818],\n ['奈良県', 1400728],\n ['滋賀県', 1410777],\n ['長崎県', 1426779],\n ['愛媛県', 1431493],\n ['山口県', 1451338],\n ['鹿児島県', 1706242],\n ['熊本県', 1817426],\n ['三重県', 1854724],\n ['岡山県', 1945276],\n ['栃木県', 2007683],\n ['群馬県', 2008068],\n ['福島県', 2029064],\n ['岐阜県', 2080773],\n ['長野県', 2152449],\n ['宮城県', 2348165],\n ['新潟県', 2374450],\n ['京都府', 2636092],\n ['広島県', 2860750],\n ['茨城県', 2969770],\n ['静岡県', 3765007],\n ['福岡県', 5071968],\n ['北海道', 5506419],\n ['兵庫県', 5588133],\n ['千葉県', 6216289],\n ['埼玉県', 7194556],\n ['愛知県', 7410719],\n ['大阪府', 8865245],\n ['神奈川県', 9048331],\n ['東京都', 13159388]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
